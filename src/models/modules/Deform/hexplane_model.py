import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.init as init
from src.utils.rigid_utils import exp_se3
import os
from src.utils.system_utils import searchForMaxIteration
from src.utils.general_utils import get_expon_lr_func
from src.utils.graphics_utils import apply_rotation, batch_quaternion_multiply
import itertools
import logging as log
from typing import Optional, Union, List, Dict, Sequence, Iterable, Collection, Callable

import time
import functools
import numpy as np


def compute_plane_smoothness(t):
    batch_size, c, h, w = t.shape
    # Convolve with a second derivative filter, in the time dimension which is dimension 2
    first_difference = t[..., 1:, :] - t[..., : h - 1, :]  # [batch, c, h-1, w]
    second_difference = (
        first_difference[..., 1:, :] - first_difference[..., : h - 2, :]
    )  # [batch, c, h-2, w]
    # Take the L2 norm of the result
    return torch.square(second_difference).mean()


def get_normalized_directions(directions):
    """SH encoding must be in the range [0, 1]

    Args:
        directions: batch of directions
    """
    return (directions + 1.0) / 2.0


def normalize_aabb(pts, aabb):
    return (pts - aabb[0]) * (2.0 / (aabb[1] - aabb[0])) - 1.0


def grid_sample_wrapper(
    grid: torch.Tensor, coords: torch.Tensor, align_corners: bool = True
) -> torch.Tensor:
    grid_dim = coords.shape[-1]

    if grid.dim() == grid_dim + 1:
        # no batch dimension present, need to add it
        grid = grid.unsqueeze(0)
    if coords.dim() == 2:
        coords = coords.unsqueeze(0)

    if grid_dim == 2 or grid_dim == 3:
        grid_sampler = F.grid_sample
    else:
        raise NotImplementedError(
            f"Grid-sample was called with {grid_dim}D data but is only "
            f"implemented for 2 and 3D data."
        )

    coords = coords.view(
        [coords.shape[0]] + [1] * (grid_dim - 1) + list(coords.shape[1:])
    )
    B, feature_dim = grid.shape[:2]
    n = coords.shape[-2]
    interp = grid_sampler(
        grid,  # [B, feature_dim, reso, ...]
        coords.float(),  # [B, 1, ..., n, grid_dim]
        align_corners=align_corners,
        mode="bilinear",
        padding_mode="border",
    )
    interp = interp.view(B, feature_dim, n).transpose(-1, -2)  # [B, n, feature_dim]
    interp = interp.squeeze()  # [B?, n, feature_dim?]
    return interp


def init_grid_param(
    grid_nd: int,
    in_dim: int,
    out_dim: int,
    reso: Sequence[int],
    a: float = 0.1,
    b: float = 0.5,
):
    assert in_dim == len(
        reso
    ), "Resolution must have same number of elements as input-dimension"
    has_time_planes = in_dim == 4
    assert grid_nd <= in_dim
    coo_combs = list(itertools.combinations(range(in_dim), grid_nd))
    grid_coefs = nn.ParameterList()
    for ci, coo_comb in enumerate(coo_combs):
        new_grid_coef = nn.Parameter(
            torch.empty([1, out_dim] + [reso[cc] for cc in coo_comb[::-1]])
        )
        if has_time_planes and 3 in coo_comb:  # Initialize time planes to 1
            nn.init.ones_(new_grid_coef)
        else:
            nn.init.uniform_(new_grid_coef, a=a, b=b)
        grid_coefs.append(new_grid_coef)

    return grid_coefs


def interpolate_ms_features(
    pts: torch.Tensor,
    ms_grids: Collection[Iterable[nn.Module]],
    grid_dimensions: int,
    concat_features: bool,
    num_levels: Optional[int],
) -> torch.Tensor:
    coo_combs = list(itertools.combinations(range(pts.shape[-1]), grid_dimensions))
    if num_levels is None:
        num_levels = len(ms_grids)
    multi_scale_interp = [] if concat_features else 0.0
    grid: nn.ParameterList
    for scale_id, grid in enumerate(ms_grids[:num_levels]):
        interp_space = 1.0
        for ci, coo_comb in enumerate(coo_combs):
            # interpolate in plane
            feature_dim = grid[ci].shape[1]  # shape of grid[ci]: 1, out_dim, *reso
            interp_out_plane = grid_sample_wrapper(grid[ci], pts[..., coo_comb]).view(
                -1, feature_dim
            )
            # compute product over planes
            interp_space = interp_space * interp_out_plane

        # combine over scales
        if concat_features:
            multi_scale_interp.append(interp_space)
        else:
            multi_scale_interp = multi_scale_interp + interp_space

    if concat_features:
        multi_scale_interp = torch.cat(multi_scale_interp, dim=-1)
    return multi_scale_interp


def initialize_weights(m):
    if isinstance(m, nn.Linear):
        # init.constant_(m.weight, 0)
        init.xavier_uniform_(m.weight, gain=1)
        if m.bias is not None:
            init.xavier_uniform_(m.weight, gain=1)
            # init.constant_(m.bias, 0)


def poc_fre(input_data, poc_buf):

    input_data_emb = (input_data.unsqueeze(-1) * poc_buf).flatten(-2)
    input_data_sin = input_data_emb.sin()
    input_data_cos = input_data_emb.cos()
    input_data_emb = torch.cat([input_data, input_data_sin, input_data_cos], -1)
    return input_data_emb


class DenseGrid(nn.Module):
    def __init__(self, channels, world_size, **kwargs):
        super(DenseGrid, self).__init__()
        self.channels = channels
        self.world_size = world_size
        # self.xyz_max = xyz_max
        # self.xyz_min = xyz_min
        # self.register_buffer('xyz_min', torch.Tensor(xyz_min))
        # self.register_buffer('xyz_max', torch.Tensor(xyz_max))
        self.grid = nn.Parameter(torch.ones([1, channels, *world_size]))

    def forward(self, xyz):
        """
        xyz: global coordinates to query
        """
        shape = xyz.shape[:-1]
        xyz = xyz.reshape(1, 1, 1, -1, 3)
        ind_norm = ((xyz - self.xyz_min) / (self.xyz_max - self.xyz_min)).flip(
            (-1,)
        ) * 2 - 1
        out = F.grid_sample(self.grid, ind_norm, mode="bilinear", align_corners=True)
        out = out.reshape(self.channels, -1).T.reshape(*shape, self.channels)
        # if self.channels == 1:
        # out = out.squeeze(-1)
        return out

    def scale_volume_grid(self, new_world_size):
        if self.channels == 0:
            self.grid = nn.Parameter(torch.ones([1, self.channels, *new_world_size]))
        else:
            self.grid = nn.Parameter(
                F.interpolate(
                    self.grid.data,
                    size=tuple(new_world_size),
                    mode="trilinear",
                    align_corners=True,
                )
            )

    def set_aabb(self, xyz_max, xyz_min):
        self.register_buffer("xyz_min", torch.Tensor(xyz_min))
        self.register_buffer("xyz_max", torch.Tensor(xyz_max))

    def get_dense_grid(self):
        return self.grid

    @torch.no_grad()
    def __isub__(self, val):
        self.grid.data -= val
        return self

    def extra_repr(self):
        return f"channels={self.channels}, world_size={self.world_size}"


class HexPlaneField(nn.Module):
    def __init__(self, bounds, planeconfig, multires) -> None:
        super().__init__()
        aabb = torch.tensor([[bounds, bounds, bounds], [-bounds, -bounds, -bounds]])
        self.aabb = nn.Parameter(aabb, requires_grad=False)
        self.grid_config = [planeconfig]
        self.multiscale_res_multipliers = multires
        self.concat_features = True

        # 1. Init planes
        self.grids = nn.ModuleList()
        self.feat_dim = 0
        for res in self.multiscale_res_multipliers:
            # initialize coordinate grid
            config = self.grid_config[0].copy()
            # Resolution fix: multi-res only on spatial planes
            config["resolution"] = [r * res for r in config["resolution"][:3]] + config[
                "resolution"
            ][3:]
            gp = init_grid_param(
                grid_nd=config["grid_dimensions"],
                in_dim=config["input_coordinate_dim"],
                out_dim=config["output_coordinate_dim"],
                reso=config["resolution"],
            )
            # shape[1] is out-dim - Concatenate over feature len for each scale
            if self.concat_features:
                self.feat_dim += gp[-1].shape[1]
            else:
                self.feat_dim = gp[-1].shape[1]
            self.grids.append(gp)
        # print(f"Initialized model grids: {self.grids}")
        print("feature_dim:", self.feat_dim)

    @property
    def get_aabb(self):
        return self.aabb[0], self.aabb[1]

    def set_aabb(self, xyz_max, xyz_min):
        aabb = torch.tensor([xyz_max, xyz_min], dtype=torch.float32)
        self.aabb = nn.Parameter(aabb, requires_grad=False)
        print("Voxel Plane: set aabb=", self.aabb)

    def get_density(self, pts: torch.Tensor, timestamps: Optional[torch.Tensor] = None):
        """Computes and returns the densities."""
        # breakpoint()
        pts = normalize_aabb(pts, self.aabb)
        pts = torch.cat((pts, timestamps), dim=-1)  # [n_rays, n_samples, 4]

        pts = pts.reshape(-1, pts.shape[-1])
        features = interpolate_ms_features(
            pts,
            ms_grids=self.grids,  # noqa
            grid_dimensions=self.grid_config[0]["grid_dimensions"],
            concat_features=self.concat_features,
            num_levels=None,
        )
        if len(features) < 1:
            features = torch.zeros((0, 1)).to(features.device)

        return features

    def forward(self, pts: torch.Tensor, timestamps: Optional[torch.Tensor] = None):

        features = self.get_density(pts, timestamps)

        return features


class Deformation(nn.Module):
    def __init__(
        self,
        D=1,
        W=128,
        input_ch=27,
        input_ch_time=9,
        grid_pe=0,
        skips=[],
        bounds=1.6,
        kplanes_config={
            "grid_dimensions": 2,
            "input_coordinate_dim": 4,
            "output_coordinate_dim": 16,
            "resolution": [64, 64, 64, 150],
        },
        multires=[1, 2, 4],
        empty_voxel=False,
        static_mlp=False,
        no_grid=False,
        no_dx=False,
        no_ds=False,
        no_dr=False,
        no_do=True,
        no_dshs=True,
        apply_rotation=False,
        sh_dim=None,
    ):
        super(Deformation, self).__init__()
        # assert False, self.D
        self.D = D
        self.W = W
        self.input_ch = input_ch
        self.input_ch_time = input_ch_time
        self.skips = skips
        self.grid_pe = grid_pe
        self.no_grid = no_grid
        self.grid = HexPlaneField(bounds, kplanes_config, multires)
        # breakpoint()
        self.args_empty_voxel = empty_voxel
        self.args_static_mlp = static_mlp
        self.args_no_dx = no_dx
        self.args_no_ds = no_ds
        self.args_no_dr = no_dr
        self.args_no_do = no_do
        self.args_no_dshs = no_dshs
        self.args_apply_rotation = apply_rotation
        # self.args_empty_voxel=True
        if self.args_empty_voxel:
            self.empty_voxel = DenseGrid(channels=1, world_size=[64, 64, 64])
        if self.args_static_mlp:
            self.static_mlp = nn.Sequential(
                nn.ReLU(), nn.Linear(self.W, self.W), nn.ReLU(), nn.Linear(self.W, 1)
            )

        self.ratio = 0
        self.sh_dim = sh_dim
        self.create_net()

    @property
    def get_aabb(self):
        return self.grid.get_aabb

    def set_aabb(self, xyz_max, xyz_min):
        print("Deformation Net Set aabb", xyz_max, xyz_min)
        self.grid.set_aabb(xyz_max, xyz_min)
        if self.args_empty_voxel:
            self.empty_voxel.set_aabb(xyz_max, xyz_min)

    def create_net(self):
        mlp_out_dim = 0
        if self.grid_pe != 0:

            grid_out_dim = self.grid.feat_dim + (self.grid.feat_dim) * 2
        else:
            grid_out_dim = self.grid.feat_dim
        if self.no_grid:
            self.feature_out = [nn.Linear(4, self.W)]
        else:
            self.feature_out = [nn.Linear(mlp_out_dim + grid_out_dim, self.W)]

        for i in range(self.D - 1):
            self.feature_out.append(nn.ReLU())
            self.feature_out.append(nn.Linear(self.W, self.W))
        self.feature_out = nn.Sequential(*self.feature_out)
        self.pos_deform = nn.Sequential(
            nn.ReLU(), nn.Linear(self.W, self.W), nn.ReLU(), nn.Linear(self.W, 3)
        )
        self.scales_deform = nn.Sequential(
            nn.ReLU(), nn.Linear(self.W, self.W), nn.ReLU(), nn.Linear(self.W, 3)
        )
        self.rotations_deform = nn.Sequential(
            nn.ReLU(), nn.Linear(self.W, self.W), nn.ReLU(), nn.Linear(self.W, 4)
        )
        self.opacity_deform = nn.Sequential(
            nn.ReLU(), nn.Linear(self.W, self.W), nn.ReLU(), nn.Linear(self.W, 1)
        )
        self.shs_deform = nn.Sequential(
            nn.ReLU(),
            nn.Linear(self.W, self.W),
            nn.ReLU(),
            nn.Linear(self.W, self.sh_dim),
        )

    def query_time(
        self, rays_pts_emb, scales_emb, rotations_emb, time_feature, time_emb
    ):

        if self.no_grid:
            h = torch.cat([rays_pts_emb[:, :3], time_emb[:, :1]], -1)
        else:

            grid_feature = self.grid(rays_pts_emb[:, :3], time_emb[:, :1])
            # breakpoint()
            if self.grid_pe > 1:
                grid_feature = poc_fre(grid_feature, self.grid_pe)
            hidden = torch.cat([grid_feature], -1)

        hidden = self.feature_out(hidden)

        return hidden

    @property
    def get_empty_ratio(self):
        return self.ratio

    def forward(
        self,
        rays_pts_emb,
        scales_emb=None,
        rotations_emb=None,
        opacity=None,
        shs_emb=None,
        time_feature=None,
        time_emb=None,
    ):
        if time_emb is None:
            return self.forward_static(rays_pts_emb[:, :3])
        else:
            return self.forward_dynamic(
                rays_pts_emb,
                scales_emb,
                rotations_emb,
                opacity,
                shs_emb,
                time_feature,
                time_emb,
            )

    def forward_static(self, rays_pts_emb):
        grid_feature = self.grid(rays_pts_emb[:, :3])
        dx = self.static_mlp(grid_feature)
        return rays_pts_emb[:, :3] + dx

    def forward_dynamic(
        self,
        rays_pts_emb,
        scales_emb,
        rotations_emb,
        opacity_emb,
        shs_emb,
        time_feature,
        time_emb,
    ):
        hidden = self.query_time(
            rays_pts_emb, scales_emb, rotations_emb, time_feature, time_emb
        )
        if self.args_static_mlp:
            mask = self.static_mlp(hidden)
        elif self.args_empty_voxel:
            mask = self.empty_voxel(rays_pts_emb[:, :3])
        else:
            mask = torch.ones_like(opacity_emb[:, 0]).unsqueeze(-1)
        # breakpoint()
        if self.args_no_dx:
            pts = rays_pts_emb[:, :3]
        else:
            dx = self.pos_deform(hidden)
            pts = torch.zeros_like(rays_pts_emb[:, :3])
            pts = rays_pts_emb[:, :3] * mask + dx
        if self.args_no_ds:

            scales = scales_emb[:, :3]
        else:
            ds = self.scales_deform(hidden)

            scales = torch.zeros_like(scales_emb[:, :3])
            scales = scales_emb[:, :3] * mask + ds

        if self.args_no_dr:
            rotations = rotations_emb[:, :4]
        else:
            dr = self.rotations_deform(hidden)

            rotations = torch.zeros_like(rotations_emb[:, :4])
            if self.args_apply_rotation:
                rotations = batch_quaternion_multiply(rotations_emb, dr)
            else:
                rotations = rotations_emb[:, :4] + dr

        if self.args_no_do:
            opacity = opacity_emb[:, :1]
        else:
            do = self.opacity_deform(hidden)

            opacity = torch.zeros_like(opacity_emb[:, :1])
            opacity = opacity_emb[:, :1] * mask + do
        if self.args_no_dshs:
            shs = shs_emb
        else:
            # assert False, "Not allowed for now as decoder version is not set"
            dshs = self.shs_deform(hidden)
            if len(shs_emb.shape) == 3:
                dshs = dshs.reshape([shs_emb.shape[0], -1, 3])

            shs = torch.zeros_like(shs_emb)
            # breakpoint()
            shs = shs_emb * mask.unsqueeze(-1) + dshs

        return pts, scales, rotations, opacity, shs

    def get_mlp_parameters(self):
        parameter_list = []
        for name, param in self.named_parameters():
            if "grid" not in name:
                parameter_list.append(param)
        return parameter_list

    def get_grid_parameters(self):
        parameter_list = []
        for name, param in self.named_parameters():
            if "grid" in name:
                parameter_list.append(param)
        return parameter_list


class deform_network(nn.Module):
    def __init__(
        self,
        # net_width:int=64,
        timebase_pe: Optional[int] = 4,
        # defor_depth: int=1,
        posbase_pe: Optional[int] = 10,
        scale_rotation_pe: Optional[int] = 2,
        opacity_pe: Optional[int] = 2,
        timenet_width: Optional[int] = 64,
        timenet_output: Optional[int] = 32,
        **kwargs,
    ):
        super(deform_network, self).__init__()
        # net_width = args.net_width
        # timebase_pe = args.timebase_pe
        # defor_depth= args.defor_depth
        # posbase_pe= args.posebase_pe
        # scale_rotation_pe = args.scale_rotation_pe
        # opacity_pe = args.opacity_pe
        # timenet_width = args.timenet_width
        # timenet_output = args.timenet_output
        # grid_pe = args.grid_pe
        times_ch = 2 * timebase_pe + 1
        self.timenet = nn.Sequential(
            nn.Linear(times_ch, timenet_width),
            nn.ReLU(),
            nn.Linear(timenet_width, timenet_output),
        )
        self.deformation_net = Deformation(
            # W=net_width,
            # D=defor_depth,
            input_ch=(3) + (3 * (posbase_pe)) * 2,
            # grid_pe=grid_pe,
            input_ch_time=timenet_output,
            **kwargs,
        )
        self.register_buffer(
            "time_poc", torch.FloatTensor([(2**i) for i in range(timebase_pe)])
        )
        self.register_buffer(
            "pos_poc", torch.FloatTensor([(2**i) for i in range(posbase_pe)])
        )
        self.register_buffer(
            "rotation_scaling_poc",
            torch.FloatTensor([(2**i) for i in range(scale_rotation_pe)]),
        )
        self.register_buffer(
            "opacity_poc", torch.FloatTensor([(2**i) for i in range(opacity_pe)])
        )
        self.apply(initialize_weights)
        # print(self)

        # move everything to cuda
        # self.timenet = self.timenet.cuda()
        # self.deformation_net = self.deformation_net.cuda()
        # self.time_poc = self.time_poc.cuda()
        # self.pos_poc = self.pos_poc.cuda()
        # self.rotation_scaling_poc =  self.rotation_scaling_poc.cuda()
        # self.opacity_poc = self.opacity_poc.cuda()

    def forward(
        self, point, scales=None, rotations=None, opacity=None, shs=None, times_sel=None
    ):
        return self.forward_dynamic(point, scales, rotations, opacity, shs, times_sel)

    @property
    def get_aabb(self):

        return self.deformation_net.get_aabb

    @property
    def get_empty_ratio(self):
        return self.deformation_net.get_empty_ratio

    def forward_static(self, points):
        points = self.deformation_net(points)
        return points

    def forward_dynamic(
        self, point, scales=None, rotations=None, opacity=None, shs=None, times_sel=None
    ):
        # times_emb = poc_fre(times_sel, self.time_poc)
        point_emb = poc_fre(point, self.pos_poc)
        scales_emb = poc_fre(scales, self.rotation_scaling_poc)
        rotations_emb = poc_fre(rotations, self.rotation_scaling_poc)
        # time_emb = poc_fre(times_sel, self.time_poc)
        # times_feature = self.timenet(time_emb)
        means3D, scales, rotations, opacity, shs = self.deformation_net(
            point_emb, scales_emb, rotations_emb, opacity, shs, None, times_sel
        )
        return means3D, scales, rotations, opacity, shs

    def get_mlp_parameters(self):
        return self.deformation_net.get_mlp_parameters() + list(
            self.timenet.parameters()
        )

    def get_grid_parameters(self):
        return self.deformation_net.get_grid_parameters()


class HexPlaneModel(nn.Module):
    def __init__(
        self,
        is_blender=False,
        deform_scale: Optional[bool] = True,
        deform_opacity: Optional[bool] = False,
        deform_feature: Optional[bool] = False,
        sh_dim=None,
        **kwargs,
    ):
        super().__init__()
        if is_blender:
            D = 0
            W = 64
            multires = [1, 2]
            kplanes_config = {
                "grid_dimensions": 2,
                "input_coordinate_dim": 4,
                "output_coordinate_dim": 16,
                "resolution": [64, 64, 64, 100],
            }
        else:
            D = 1
            W = 128
            multires = [1, 2, 4]
            kplanes_config = {
                "grid_dimensions": 2,
                "input_coordinate_dim": 4,
                "output_coordinate_dim": 32,
                "resolution": [64, 64, 64, 150],
            }
        no_ds = not deform_scale
        no_do = not deform_opacity
        no_dshs = not deform_feature

        self._deformation = deform_network(
            D=D,
            W=W,
            multires=multires,
            kplanes_config=kplanes_config,
            no_ds=no_ds,
            no_do=no_do,
            no_dshs=no_dshs,
            sh_dim=sh_dim,
            **kwargs,
        )
        # assert False, "Under construction for deform mode..."

    def forward(self, inp: Dict, time: float):
        time = (
            torch.tensor([time])
            .to(inp["means3D"].device)
            .view(1, 1)
            .repeat(inp["means3D"].shape[0], 1)
        )
        means3D_final, scales_final, rotations_final, opacity_final, shs_final = (
            self._deformation(
                inp["means3D"],
                inp["scales"],
                inp["rotations"],
                inp["opacity"],
                inp["shs"],
                time,
            )
        )
        return means3D_final, rotations_final, scales_final, opacity_final, shs_final

    def compute_regulation(
        self, time_smoothness_weight, l1_time_planes_weight, plane_tv_weight
    ):
        return (
            plane_tv_weight * self._plane_regulation()
            + time_smoothness_weight * self._time_regulation()
            + l1_time_planes_weight * self._l1_regulation()
        )

    def _plane_regulation(self):
        multi_res_grids = self._deformation.deformation_net.grid.grids
        total = 0
        # model.grids is 6 x [1, rank * F_dim, reso, reso]
        for grids in multi_res_grids:
            if len(grids) == 3:
                time_grids = []
            else:
                time_grids = [0, 1, 3]
            for grid_id in time_grids:
                total += compute_plane_smoothness(grids[grid_id])
        return total

    def _time_regulation(self):
        multi_res_grids = self._deformation.deformation_net.grid.grids
        total = 0
        # model.grids is 6 x [1, rank * F_dim, reso, reso]
        for grids in multi_res_grids:
            if len(grids) == 3:
                time_grids = []
            else:
                time_grids = [2, 4, 5]
            for grid_id in time_grids:
                total += compute_plane_smoothness(grids[grid_id])
        return total

    def _l1_regulation(self):
        # model.grids is 6 x [1, rank * F_dim, reso, reso]
        multi_res_grids = self._deformation.deformation_net.grid.grids

        total = 0.0
        for grids in multi_res_grids:
            if len(grids) == 3:
                continue
            else:
                # These are the spatiotemporal grids
                spatiotemporal_grids = [2, 4, 5]
            for grid_id in spatiotemporal_grids:
                total += torch.abs(1 - grids[grid_id]).mean()
        return total

    def train_setting(
        self,
        spatial_lr_scale: float,
        grid_lr_init: float,
        grid_lr_final: float,
        grid_lr_delay_mult: float,
        grid_lr_max_steps: float,
        deform_lr_init: float,
        deform_lr_final: float,
        deform_lr_delay_mult: float,
        deform_lr_max_steps: float,
        **kwargs,
    ):
        l = [
            {
                "params": list(self._deformation.get_mlp_parameters()),
                "lr": deform_lr_init * spatial_lr_scale,
                "name": "deform",
            },
            {
                "params": list(self._deformation.get_grid_parameters()),
                "lr": grid_lr_init * spatial_lr_scale,
                "name": "grid",
            },
        ]
        deform_optimizer = torch.optim.Adam(l, lr=0.0, eps=1e-15)

        deformation_scheduler_args_dict = {
            "deform": get_expon_lr_func(
                lr_init=deform_lr_init * spatial_lr_scale,
                lr_final=deform_lr_final * spatial_lr_scale,
                lr_delay_mult=deform_lr_delay_mult,
                max_steps=deform_lr_max_steps,
            ),
            "grid": get_expon_lr_func(
                lr_init=grid_lr_init * spatial_lr_scale,
                lr_final=grid_lr_final * spatial_lr_scale,
                lr_delay_mult=grid_lr_delay_mult,
                max_steps=grid_lr_max_steps,
            ),
        }
        return deform_optimizer, deformation_scheduler_args_dict
